{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de74014-4810-4097-8751-20c91f058c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from astropy.io import fits\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, progress\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, random_split\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "328a0201-c139-4dab-9f93-211f6dc42ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bfe0a6d-7373-4094-8094-ea854b242df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = True\n",
    "augmentation_strategy = T.TrivialAugmentWide()\n",
    "model_name = \"regnet\"\n",
    "optimiser = optim.AdamW\n",
    "num_channels = 1\n",
    "lr = 1e-4\n",
    "num_outputs = 1\n",
    "xy_size = 380\n",
    "batch_size = 32\n",
    "num_epochs = 30\n",
    "test_split = 0.2\n",
    "val_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ff55ff-741a-4e9b-b2f1-92bd6c479364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n"
     ]
    }
   ],
   "source": [
    "if gpu:\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        accelerator = \"gpu\"\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        accelerator = \"gpu\"\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        accelerator = \"cpu\"\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    accelerator = \"cpu\"\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9eec897-4249-4faa-8029-a1c7a5d1293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_channels(arr):\n",
    "    arr -= np.min(arr)\n",
    "    arr /= np.max(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d70739cf-c593-4774-a693-7cde6770b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fits(\n",
    "    folder_path: os.PathLike,\n",
    "    labels_dict: dict[str, np.ndarray],\n",
    "    normalise: bool = True,\n",
    "):\n",
    "    data_names = os.listdir(folder_path)\n",
    "    data_names = np.array([x for x in data_names if \".fits\" in x])\n",
    "    run_nums = np.array([int(x.split(\"planet\")[1].split(\"_\")[0]) for x in data_names])\n",
    "    order = np.argsort(run_nums)\n",
    "    run_nums = run_nums[order]\n",
    "    data_names = data_names[order]\n",
    "    data = dict([(name, fits.open(f\"{folder_path}/{name}\")[0].data.squeeze()[0]) for name in data_names])\n",
    "    if normalise:\n",
    "        for im in data.values():\n",
    "            normalise_channels(im)\n",
    "    nums = {}\n",
    "    for (name, run) in zip(data_names, run_nums):\n",
    "        label = labels_dict[\"n\"][np.where(labels_dict[\"runs\"] == run)][0]\n",
    "        nums[name] = int(label)\n",
    "        labels[name] = int(label > 0)\n",
    "    xy_dim = data[data_names[0]].shape[1]\n",
    "    X = np.empty((len(data_names), 1, xy_dim, xy_dim))\n",
    "    y = np.empty((len(data_names), 1))\n",
    "    for i, name in enumerate(data_names):\n",
    "        X[i, :, :] = data[name]\n",
    "        y[i, 0] = labels[name]\n",
    "    return (X.astype(np.float32), y.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3906cbe-9d40-4290-a2a0-7868609cc395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(path):\n",
    "    label_df = pd.read_csv(\"train_info.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "    runs = label_df.run.to_numpy()\n",
    "    Ns = label_df.n.to_numpy()\n",
    "    return {\n",
    "        \"runs\": runs,\n",
    "        \"n\": Ns\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba370d5c-2d68-46fb-ae24-7c70ba99f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_labels(\"train_info.csv\")\n",
    "X, y = load_fits(\"Full_Train_Data\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1815dd6a-d0cc-461d-a614-57a8babd8b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_split)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a088d34-28ba-400d-81d4-7d916c299002",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiskDataset(Dataset):\n",
    "\n",
    "    \"\"\"Data loader\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        transform: list,\n",
    "        device: torch.device,\n",
    "        num_workers: int = 13,\n",
    "    ) -> None:\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        self.num_workers = num_workers\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx) -> torch.Tensor:\n",
    "        x_, y_ = self.X[idx], self.y[idx]\n",
    "\n",
    "        x_, y_ = torch.from_numpy(x_),\\\n",
    "                torch.from_numpy(y_)\n",
    "\n",
    "        if self.transform:\n",
    "            x_ = self.transform(x_)\n",
    "        return x_.to(self.device), y_.to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472a8e76-b5c3-44ac-a889-1b217f7b0692",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize((xy_size, xy_size), antialias=True),\n",
    "    T.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "if augmentation_strategy is not None:\n",
    "    train_transform = T.Compose(\n",
    "        [\n",
    "            augmentation_strategy,\n",
    "            transform\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    train_transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff878627-2c9e-4de0-82e1-7ee21c977f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DiskDataset(X_train, y_train, device=device, transform=train_transform)\n",
    "val_data = DiskDataset(X_val, y_val, device=device, transform=transform)\n",
    "test_data = DiskDataset(X_test, y_test, device=device, transform=transform)\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d9f68ce-cc78-4816-9e6f-ea6d59743105",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_channels:int,\n",
    "        xy_dim: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Initialize containers to store outputs\n",
    "        self.validation_outputs = []\n",
    "        self.test_outputs = []\n",
    "\n",
    "        self.example_input_array = torch.randn((1, num_channels, xy_dim, xy_dim)).float()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _process_batch(self, batch, when: str = \"train\"):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(f\"{when}_loss\", loss)\n",
    "        if when != \"train\":\n",
    "            return {f\"{when}_loss\": loss, \"y_hat\": y_hat, \"y\": y}\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._process_batch(batch, when=\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self._process_batch(batch, when=\"val\")\n",
    "        self.validation_outputs.append(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        outputs = self._process_batch(batch, when=\"test\")\n",
    "        self.test_outputs.append(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optimiser(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "        )\n",
    "\n",
    "    def _roc_epoch_end(self, outputs, when: str = \"val\"):\n",
    "        \"\"\"Logs AUC during validation/testing\"\"\"\n",
    "        y_hat = torch.cat([x[\"y_hat\"] for x in outputs]).detach().cpu().numpy()\n",
    "        y = torch.cat([x[\"y\"] for x in outputs]).detach().cpu().numpy()\n",
    "        auc = self.calculate_auc(y_hat, y)\n",
    "        self.log(f\"{when}_auc\", auc)\n",
    "\n",
    "    def on_validation_epoch_end(self,):\n",
    "        self._roc_epoch_end(self.validation_outputs, when=\"val\")\n",
    "        self.validation_outputs.clear()\n",
    "\n",
    "    def on_test_epoch_end(self,):\n",
    "        self._roc_epoch_end(self.test_outputs, when=\"test\")\n",
    "        self.test_outputs.clear()\n",
    "\n",
    "    def calculate_auc(self, y_hat, y):\n",
    "        # Apply sigmoid to predictions if using BCEWithLogitsLoss\n",
    "        y_hat = torch.sigmoid(torch.tensor(y_hat).float()).numpy()\n",
    "        auc = roc_auc_score(y, y_hat)\n",
    "        return np.float32(auc)\n",
    "    \n",
    "        \n",
    "\n",
    "class CustomEfficientNetv2(CustomModel):\n",
    "    def __init__(self,\n",
    "                 num_channels: int,\n",
    "                 num_outputs: int,\n",
    "                 lr: float,\n",
    "                 xy_dim: int,\n",
    "                ):\n",
    "        super().__init__(num_channels, xy_dim)\n",
    "        self.model = torchvision.models.efficientnet_v2_s()\n",
    "\n",
    "        # Modify the first convolutional layer if input channels are different from 3\n",
    "        if num_channels != 3:\n",
    "            self.model.features[0][0] = nn.Conv2d(num_channels,\n",
    "                                                  self.model.features[0][0].out_channels,\n",
    "                                                  kernel_size=self.model.features[0][0].kernel_size,\n",
    "                                                  stride=self.model.features[0][0].stride,\n",
    "                                                  padding=self.model.features[0][0].padding,\n",
    "                                                  bias=False,\n",
    "                                                 )\n",
    "            \n",
    "        in_features = self.model.classifier[1].in_features\n",
    "        self.model.classifier[1] = nn.Linear(in_features, num_outputs)\n",
    "\n",
    "class CustomRegNet(CustomModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_channels: int,\n",
    "        num_outputs: int,\n",
    "        lr: float,\n",
    "        xy_dim: int,\n",
    "    ):\n",
    "        super().__init__(num_channels, xy_dim)\n",
    "        self.model = torchvision.models.regnet_y_16gf()\n",
    "\n",
    "        # Replace the first conv layer in the stem if num_channels != 3\n",
    "        if num_channels != 3:\n",
    "            old_conv = self.model.stem[0]\n",
    "            self.model.stem[0] = nn.Conv2d(\n",
    "                in_channels=num_channels,\n",
    "                out_channels=old_conv.out_channels,\n",
    "                kernel_size=old_conv.kernel_size,\n",
    "                stride=old_conv.stride,\n",
    "                padding=old_conv.padding,\n",
    "                bias=old_conv.bias is not None\n",
    "            )\n",
    "\n",
    "        in_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(in_features, num_outputs)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cdcbe89-0ec9-48f7-8b67-3b37a3eb04a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"efficientnet\":\n",
    "    model = CustomEfficientNetv2(\n",
    "        num_channels=num_channels,\n",
    "        num_outputs=num_outputs,\n",
    "        lr=lr,\n",
    "        xy_dim=xy_size,\n",
    "    )\n",
    "elif model_name == \"regnet\":\n",
    "    model = CustomRegNet(\n",
    "        num_channels=num_channels,\n",
    "        num_outputs=num_outputs,\n",
    "        lr=lr,\n",
    "        xy_dim=xy_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a060dd6-58a2-4192-92cd-0ac41a9e35ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/jamesmitchell-white/Documents/GitHub/DeepLearnHackathon/ExoplanetSearchChallenge/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    devices=1,\n",
    "    accelerator=accelerator,\n",
    "    max_epochs=num_epochs,\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[\n",
    "        LearningRateMonitor(\"epoch\"),\n",
    "        progress.TQDMProgressBar(refresh_rate=1),\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_auc\",\n",
    "            min_delta=0,\n",
    "            patience=20,\n",
    "            verbose=False,\n",
    "            mode=\"min\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "trainer.logger._log_graph = True\n",
    "trainer.logger._default_hp_metric = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d7ad11-d385-4b48-8e8c-244d872ca70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type              | Params | Mode  | In sizes         | Out sizes\n",
      "---------------------------------------------------------------------------------------\n",
      "0 | criterion | BCEWithLogitsLoss | 0      | train | ?                | ?        \n",
      "1 | model     | RegNet            | 80.6 M | train | [1, 1, 380, 380] | [1, 1]   \n",
      "---------------------------------------------------------------------------------------\n",
      "80.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "80.6 M    Total params\n",
      "322.270   Total estimated model params size (MB)\n",
      "385       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721c52e8a17342e4bf82347eda69eb2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesmitchell-white/Documents/GitHub/DeepLearnHackathon/ExoplanetSearchChallenge/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=13` in the `DataLoader` to improve performance.\n",
      "/Users/jamesmitchell-white/Documents/GitHub/DeepLearnHackathon/ExoplanetSearchChallenge/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=13` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e789fbd7b04568bf27a9d725f89f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e274a78201c54ec29f18749db68ece28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "# fit the model\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f9346c-05f9-49e3-ac12-63c6872a13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "results = []\n",
    "\n",
    "for X_batch in test_loader:\n",
    "    X_batch = X_batch[0]  # DataLoader returns a tuple\n",
    "    with torch.no_grad():\n",
    "        outputs = torch.sigmoid(model(X_batch)).cpu()\n",
    "    batch_results = outputs.detach().numpy().squeeze()\n",
    "    results.append(batch_results)\n",
    "\n",
    "y_pred = np.concatenate(results, axis=0)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "accuracy = np.sum([round(y_pred[i]) == y_test[i] for i in range(len(y_test))]) / len(y_test)\n",
    "\n",
    "print(f\"Accuracy of {accuracy:.2}. AUC of {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ef4371-114f-4a98-957a-eeaa3240cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10., 7.5))\n",
    "\n",
    "plt.plot(fpr, tpr, lw=3, c=\"steelblue\")\n",
    "plt.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100),\n",
    "         c=\"gray\", ls=\"--\", alpha=0.5, lw=3,\n",
    "         )\n",
    "\n",
    "plt.xlabel(\"FPR\", fontsize=14)\n",
    "plt.ylabel(\"TPR\", fontsize=14)\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
